<center><a href="https://gitlab.com/petsc/petsc/-/blob/c7d19d7b3f2d9e6411c648820d1207320e4154c7/src/vec/is/sf/impls/basic/allgatherv/sfallgatherv.c">Actual source code: sfallgatherv.c</a></center><br>

<html>
<head>
<title></title>
<meta name="generator" content="c2html 0.9.4">
<meta name="date" content="2023-03-30T15:47:26+00:00">
</head>

<body bgcolor="#FFFFFF">
<pre width="80">
<a name="line1">  1: </a>#include <A href="sfallgatherv.h.html">&lt;../src/vec/is/sf/impls/basic/allgatherv/sfallgatherv.h&gt;</A>

<a name="line3">  3: </a><strong><font color="#4169E1">PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFBcastBegin_Gatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a>, MPI_Datatype, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a>, const void *, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a>, void *, MPI_Op)</font></strong>;

<a name="line5">  5: </a><font color="#B22222">/* <a href="../../../../../../docs/manualpages/PetscSF/PetscSFGetGraph.html">PetscSFGetGraph</a> is non-collective. An implementation should not have collective calls */</font>
<a name="line6">  6: </a><strong><font color="#4169E1"><a name="PetscSFGetGraph_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFGetGraph_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *nroots, <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *nleaves, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **ilocal, const <a href="../../../../../../docs/manualpages/PetscSF/PetscSFNode.html">PetscSFNode</a> **iremote)</font></strong>
<a name="line7">  7: </a>{
<a name="line8">  8: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>        i, j, k;
<a name="line9">  9: </a>  const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *range;
<a name="line10"> 10: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>     size;

<a name="line12"> 12: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(<a href="../../../../../../docs/manualpages/Sys/PetscObjectComm.html">PetscObjectComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf), &amp;size);
<a name="line13"> 13: </a>  <font color="#4169E1">if</font> (nroots) *nroots = sf-&gt;nroots;
<a name="line14"> 14: </a>  <font color="#4169E1">if</font> (nleaves) *nleaves = sf-&gt;nleaves;
<a name="line15"> 15: </a>  <font color="#4169E1">if</font> (ilocal) *ilocal = NULL; <font color="#B22222">/* Contiguous leaves */</font>
<a name="line16"> 16: </a>  <font color="#4169E1">if</font> (iremote) {
<a name="line17"> 17: </a>    <font color="#4169E1">if</font> (!sf-&gt;remote &amp;&amp; sf-&gt;nleaves) { <font color="#B22222">/* The &amp;&amp; sf-&gt;nleaves makes sfgatherv able to inherit this routine */</font>
<a name="line18"> 18: </a>      <a href="../../../../../../docs/manualpages/IS/PetscLayoutGetRanges.html">PetscLayoutGetRanges</a>(sf-&gt;map, &amp;range);
<a name="line19"> 19: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(sf-&gt;nleaves, &amp;sf-&gt;remote);
<a name="line20"> 20: </a>      sf-&gt;remote_alloc = sf-&gt;remote;
<a name="line21"> 21: </a>      <font color="#4169E1">for</font> (i = 0; i &lt; size; i++) {
<a name="line22"> 22: </a>        <font color="#4169E1">for</font> (j = range[i], k = 0; j &lt; range[i + 1]; j++, k++) {
<a name="line23"> 23: </a>          sf-&gt;remote[j].rank  = i;
<a name="line24"> 24: </a>          sf-&gt;remote[j].index = k;
<a name="line25"> 25: </a>        }
<a name="line26"> 26: </a>      }
<a name="line27"> 27: </a>    }
<a name="line28"> 28: </a>    *iremote = sf-&gt;remote;
<a name="line29"> 29: </a>  }
<a name="line30"> 30: </a>  <font color="#4169E1">return</font> 0;
<a name="line31"> 31: </a>}

<a name="line33"> 33: </a><strong><font color="#4169E1"><a name="PetscSFSetUp_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFSetUp_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf)</font></strong>
<a name="line34"> 34: </a>{
<a name="line35"> 35: </a>  PetscSF_Allgatherv *dat = (PetscSF_Allgatherv *)sf-&gt;data;
<a name="line36"> 36: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>         size;
<a name="line37"> 37: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>            i;
<a name="line38"> 38: </a>  const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>     *range;
<a name="line39"> 39: </a>  <a href="../../../../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>            comm;

<a name="line41"> 41: </a>  PetscSFSetUp_Allgather(sf);
<a name="line42"> 42: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscObjectGetComm.html">PetscObjectGetComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, &amp;comm);
<a name="line43"> 43: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line44"> 44: </a>  <font color="#4169E1">if</font> (sf-&gt;nleaves) { <font color="#B22222">/* This if (sf-&gt;nleaves) test makes sfgatherv able to inherit this routine */</font>
<a name="line45"> 45: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscBool.html">PetscBool</a> isallgatherv = <a href="../../../../../../docs/manualpages/Sys/PETSC_FALSE.html">PETSC_FALSE</a>;

<a name="line47"> 47: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(size, &amp;dat-&gt;recvcounts);
<a name="line48"> 48: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(size, &amp;dat-&gt;displs);
<a name="line49"> 49: </a>    <a href="../../../../../../docs/manualpages/IS/PetscLayoutGetRanges.html">PetscLayoutGetRanges</a>(sf-&gt;map, &amp;range);

<a name="line51"> 51: </a>    <font color="#4169E1">for</font> (i = 0; i &lt; size; i++) {
<a name="line52"> 52: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(range[i], &amp;dat-&gt;displs[i]);
<a name="line53"> 53: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(range[i + 1] - range[i], &amp;dat-&gt;recvcounts[i]);
<a name="line54"> 54: </a>    }

<a name="line56"> 56: </a>    <font color="#B22222">/* check if we actually have a one-to-all pattern */</font>
<a name="line57"> 57: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscObjectTypeCompare.html">PetscObjectTypeCompare</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, PETSCSFALLGATHERV, &amp;isallgatherv);
<a name="line58"> 58: </a>    <font color="#4169E1">if</font> (isallgatherv) {
<a name="line59"> 59: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> rank, nRanksWithZeroRoots;

<a name="line61"> 61: </a>      nRanksWithZeroRoots = (sf-&gt;nroots == 0) ? 1 : 0; <font color="#B22222">/* I have no roots */</font>
<a name="line62"> 62: </a>      <a href="../../../../../../docs/manualpages/Sys/MPIU_Allreduce.html">MPIU_Allreduce</a>(MPI_IN_PLACE, &amp;nRanksWithZeroRoots, 1, MPI_INT, MPI_SUM, comm);
<a name="line63"> 63: </a>      <font color="#4169E1">if</font> (nRanksWithZeroRoots == size - 1) { <font color="#B22222">/* Only one rank has roots, which indicates a bcast pattern */</font>
<a name="line64"> 64: </a>        dat-&gt;bcast_pattern = <a href="../../../../../../docs/manualpages/Sys/PETSC_TRUE.html">PETSC_TRUE</a>;
<a name="line65"> 65: </a>        <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line66"> 66: </a>        dat-&gt;bcast_root = sf-&gt;nroots &gt; 0 ? rank : -1;
<a name="line67"> 67: </a>        <a href="../../../../../../docs/manualpages/Sys/MPIU_Allreduce.html">MPIU_Allreduce</a>(MPI_IN_PLACE, &amp;dat-&gt;bcast_root, 1, MPI_INT, MPI_MAX, comm);
<a name="line68"> 68: </a>      }
<a name="line69"> 69: </a>    }
<a name="line70"> 70: </a>  }
<a name="line71"> 71: </a>  <font color="#4169E1">return</font> 0;
<a name="line72"> 72: </a>}

<a name="line74"> 74: </a><strong><font color="#4169E1"><a name="PetscSFReset_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFReset_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf)</font></strong>
<a name="line75"> 75: </a>{
<a name="line76"> 76: </a>  PetscSF_Allgatherv *dat  = (PetscSF_Allgatherv *)sf-&gt;data;
<a name="line77"> 77: </a>  PetscSFLink         link = dat-&gt;avail, next;

<a name="line79"> 79: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(dat-&gt;iranks);
<a name="line80"> 80: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(dat-&gt;ioffset);
<a name="line81"> 81: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(dat-&gt;irootloc);
<a name="line82"> 82: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(dat-&gt;recvcounts);
<a name="line83"> 83: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(dat-&gt;displs);
<a name="line85"> 85: </a>  <font color="#4169E1">for</font> (; link; link = next) {
<a name="line86"> 86: </a>    next = link-&gt;next;
<a name="line87"> 87: </a>    PetscSFLinkDestroy(sf, link);
<a name="line88"> 88: </a>  }
<a name="line89"> 89: </a>  dat-&gt;avail = NULL;
<a name="line90"> 90: </a>  <font color="#4169E1">return</font> 0;
<a name="line91"> 91: </a>}

<a name="line93"> 93: </a><strong><font color="#4169E1"><a name="PetscSFDestroy_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFDestroy_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf)</font></strong>
<a name="line94"> 94: </a>{
<a name="line95"> 95: </a>  PetscSFReset_Allgatherv(sf);
<a name="line96"> 96: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(sf-&gt;data);
<a name="line97"> 97: </a>  <font color="#4169E1">return</font> 0;
<a name="line98"> 98: </a>}

<a name="line100">100: </a><strong><font color="#4169E1"><a name="PetscSFBcastBegin_Allgatherv"></a>static <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFBcastBegin_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> rootmtype, const void *rootdata, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> leafmtype, void *leafdata, MPI_Op op)</font></strong>
<a name="line101">101: </a>{
<a name="line102">102: </a>  PetscSFLink         link;
<a name="line103">103: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>         sendcount, rank;
<a name="line104">104: </a>  <a href="../../../../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>            comm;
<a name="line105">105: </a>  void               *rootbuf = NULL, *leafbuf = NULL;
<a name="line106">106: </a>  MPI_Request        *req;
<a name="line107">107: </a>  PetscSF_Allgatherv *dat = (PetscSF_Allgatherv *)sf-&gt;data;

<a name="line109">109: </a>  PetscSFLinkCreate(sf, unit, rootmtype, rootdata, leafmtype, leafdata, op, PETSCSF_BCAST, &amp;link);
<a name="line110">110: </a>  PetscSFLinkPackRootData(sf, link, PETSCSF_REMOTE, rootdata);
<a name="line111">111: </a>  PetscSFLinkCopyRootBufferInCaseNotUseGpuAwareMPI(sf, link, <a href="../../../../../../docs/manualpages/Sys/PETSC_TRUE.html">PETSC_TRUE</a> <font color="#B22222">/* device2host before sending */</font>);
<a name="line112">112: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscObjectGetComm.html">PetscObjectGetComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, &amp;comm);
<a name="line113">113: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line114">114: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(sf-&gt;nroots, &amp;sendcount);
<a name="line115">115: </a>  PetscSFLinkGetMPIBuffersAndRequests(sf, link, PETSCSF_../../../../../..2LEAF, &amp;rootbuf, &amp;leafbuf, &amp;req, NULL);

<a name="line117">117: </a>  <font color="#4169E1">if</font> (dat-&gt;bcast_pattern &amp;&amp; rank == dat-&gt;bcast_root) (*link-&gt;Memcpy)(link, link-&gt;leafmtype_mpi, leafbuf, link-&gt;rootmtype_mpi, rootbuf, (size_t)sendcount * link-&gt;unitbytes);
<a name="line118">118: </a>  <font color="#B22222">/* Ready the buffers for MPI */</font>
<a name="line119">119: </a>  PetscSFLinkSyncStreamBeforeCallMPI(sf, link, PETSCSF_../../../../../..2LEAF);
<a name="line120">120: </a>  <font color="#4169E1">if</font> (dat-&gt;bcast_pattern) MPIU_Ibcast(leafbuf, sf-&gt;nleaves, unit, dat-&gt;bcast_root, comm, req);
<a name="line121">121: </a>  <font color="#4169E1">else</font> MPIU_Iallgatherv(rootbuf, sendcount, unit, leafbuf, dat-&gt;recvcounts, dat-&gt;displs, unit, comm, req);
<a name="line122">122: </a>  <font color="#4169E1">return</font> 0;
<a name="line123">123: </a>}

<a name="line125">125: </a><strong><font color="#4169E1"><a name="PetscSFReduceBegin_Allgatherv"></a>static <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFReduceBegin_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> leafmtype, const void *leafdata, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> rootmtype, void *rootdata, MPI_Op op)</font></strong>
<a name="line126">126: </a>{
<a name="line127">127: </a>  PetscSFLink         link;
<a name="line128">128: </a>  PetscSF_Allgatherv *dat = (PetscSF_Allgatherv *)sf-&gt;data;
<a name="line129">129: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>            rstart;
<a name="line130">130: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>         rank, count, recvcount;
<a name="line131">131: </a>  <a href="../../../../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>            comm;
<a name="line132">132: </a>  void               *rootbuf = NULL, *leafbuf = NULL;
<a name="line133">133: </a>  MPI_Request        *req;

<a name="line135">135: </a>  PetscSFLinkCreate(sf, unit, rootmtype, rootdata, leafmtype, leafdata, op, PETSCSF_REDUCE, &amp;link);
<a name="line136">136: </a>  <font color="#4169E1">if</font> (op == MPI_REPLACE) {
<a name="line137">137: </a>    <font color="#B22222">/* REPLACE is only meaningful when all processes have the same leafdata to reduce. Therefore copying from local leafdata is fine */</font>
<a name="line138">138: </a>    <a href="../../../../../../docs/manualpages/IS/PetscLayoutGetRange.html">PetscLayoutGetRange</a>(sf-&gt;map, &amp;rstart, NULL);
<a name="line139">139: </a>    (*link-&gt;Memcpy)(link, rootmtype, rootdata, leafmtype, (const char *)leafdata + (size_t)rstart * link-&gt;unitbytes, (size_t)sf-&gt;nroots * link-&gt;unitbytes);
<a name="line140">140: </a>    <font color="#4169E1">if</font> (PetscMemTypeDevice(leafmtype) &amp;&amp; PetscMemTypeHost(rootmtype)) (*link-&gt;SyncStream)(link);
<a name="line141">141: </a>  } <font color="#4169E1">else</font> {
<a name="line142">142: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscObjectGetComm.html">PetscObjectGetComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, &amp;comm);
<a name="line143">143: </a>    PetscSFLinkPackLeafData(sf, link, PETSCSF_REMOTE, leafdata);
<a name="line144">144: </a>    PetscSFLinkCopyLeafBufferInCaseNotUseGpuAwareMPI(sf, link, <a href="../../../../../../docs/manualpages/Sys/PETSC_TRUE.html">PETSC_TRUE</a> <font color="#B22222">/* device2host before sending */</font>);
<a name="line145">145: </a>    PetscSFLinkGetMPIBuffersAndRequests(sf, link, PETSCSF_LEAF2../../../../../.., &amp;rootbuf, &amp;leafbuf, &amp;req, NULL);
<a name="line146">146: </a>    PetscSFLinkSyncStreamBeforeCallMPI(sf, link, PETSCSF_LEAF2../../../../../..);
<a name="line147">147: </a>    <font color="#4169E1">if</font> (dat-&gt;bcast_pattern) {
<a name="line148">148: </a><font color="#A020F0">#if defined(PETSC_HAVE_OMPI_MAJOR_VERSION) </font><font color="#B22222">/* Workaround: cuda-aware OpenMPI-4.1.3 does not support <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ireduce.html#MPI_Ireduce">MPI_Ireduce</a>() with device buffers */</font><font color="#A020F0"></font>
<a name="line149">149: </a>      *req = MPI_REQUEST_NULL;             <font color="#B22222">/* Set NULL so that we can safely <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Wait.html#MPI_Wait">MPI_Wait</a>(req) */</font>
<a name="line150">150: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Reduce.html#MPI_Reduce">MPI_Reduce</a>(leafbuf, rootbuf, sf-&gt;nleaves, unit, op, dat-&gt;bcast_root, comm);
<a name="line151">151: </a><font color="#A020F0">#else</font>
<a name="line152">152: </a>      MPIU_Ireduce(leafbuf, rootbuf, sf-&gt;nleaves, unit, op, dat-&gt;bcast_root, comm, req);
<a name="line153">153: </a><font color="#A020F0">#endif</font>
<a name="line154">154: </a>    } <font color="#4169E1">else</font> { <font color="#B22222">/* Reduce leafdata, then scatter to rootdata */</font>
<a name="line155">155: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line156">156: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(dat-&gt;rootbuflen[PETSCSF_REMOTE], &amp;recvcount);
<a name="line157">157: </a>      <font color="#B22222">/* Allocate a separate leaf buffer on rank 0 */</font>
<a name="line158">158: </a>      <font color="#4169E1">if</font> (rank == 0 &amp;&amp; !link-&gt;leafbuf_alloc[PETSCSF_REMOTE][link-&gt;leafmtype_mpi]) {
<a name="line159">159: </a>        PetscSFMalloc(sf, link-&gt;leafmtype_mpi, sf-&gt;leafbuflen[PETSCSF_REMOTE] * link-&gt;unitbytes, (void **)&amp;link-&gt;leafbuf_alloc[PETSCSF_REMOTE][link-&gt;leafmtype_mpi]);
<a name="line160">160: </a>      }
<a name="line161">161: </a>      <font color="#B22222">/* In case we already copied leafdata from device to host (i.e., no use_gpu_aware_mpi), we need to adjust leafbuf on rank 0 */</font>
<a name="line162">162: </a>      <font color="#4169E1">if</font> (rank == 0 &amp;&amp; link-&gt;leafbuf_alloc[PETSCSF_REMOTE][link-&gt;leafmtype_mpi] == leafbuf) leafbuf = MPI_IN_PLACE;
<a name="line163">163: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(sf-&gt;nleaves * link-&gt;bs, &amp;count);
<a name="line164">164: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Reduce.html#MPI_Reduce">MPI_Reduce</a>(leafbuf, link-&gt;leafbuf_alloc[PETSCSF_REMOTE][link-&gt;leafmtype_mpi], count, link-&gt;basicunit, op, 0, comm); <font color="#B22222">/* Must do reduce with MPI builtin datatype basicunit */</font>
<a name="line165">165: </a>      MPIU_Iscatterv(link-&gt;leafbuf_alloc[PETSCSF_REMOTE][link-&gt;leafmtype_mpi], dat-&gt;recvcounts, dat-&gt;displs, unit, rootbuf, recvcount, unit, 0, comm, req);
<a name="line166">166: </a>    }
<a name="line167">167: </a>  }
<a name="line168">168: </a>  <font color="#4169E1">return</font> 0;
<a name="line169">169: </a>}

<a name="line171">171: </a><strong><font color="#4169E1"><a name="PetscSFReduceEnd_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFReduceEnd_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, const void *leafdata, void *rootdata, MPI_Op op)</font></strong>
<a name="line172">172: </a>{
<a name="line173">173: </a>  PetscSFLink link;

<a name="line175">175: </a>  <font color="#4169E1">if</font> (op == MPI_REPLACE) {
<a name="line176">176: </a>    <font color="#B22222">/* A rare case happens when op is MPI_REPLACE, using GPUs but no GPU aware MPI. In PetscSFReduceBegin_Allgather(v),</font>
<a name="line177">177: </a><font color="#B22222">      we did a device to device copy and in effect finished the communication. But in PetscSFLinkFinishCommunication()</font>
<a name="line178">178: </a><font color="#B22222">      of PetscSFReduceEnd_Basic(), it thinks since there is rootbuf, it calls PetscSFLinkCopyRootBufferInCaseNotUseGpuAwareMPI().</font>
<a name="line179">179: </a><font color="#B22222">      It does a host to device memory copy on rootbuf, wrongly overwriting the results. So we don't overload</font>
<a name="line180">180: </a><font color="#B22222">      PetscSFReduceEnd_Basic() in this case, and just reclaim the link.</font>
<a name="line181">181: </a><font color="#B22222">     */</font>
<a name="line182">182: </a>    PetscSFLinkGetInUse(sf, unit, rootdata, leafdata, <a href="../../../../../../docs/manualpages/Sys/PetscCopyMode.html">PETSC_OWN_POINTER</a>, &amp;link);
<a name="line183">183: </a>    PetscSFLinkReclaim(sf, &amp;link);
<a name="line184">184: </a>  } <font color="#4169E1">else</font> {
<a name="line185">185: </a>    PetscSFReduceEnd_Basic(sf, unit, leafdata, rootdata, op);
<a name="line186">186: </a>  }
<a name="line187">187: </a>  <font color="#4169E1">return</font> 0;
<a name="line188">188: </a>}

<a name="line190">190: </a><strong><font color="#4169E1"><a name="PetscSFBcastToZero_Allgatherv"></a>static <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFBcastToZero_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> rootmtype, const void *rootdata, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> leafmtype, void *leafdata)</font></strong>
<a name="line191">191: </a>{
<a name="line192">192: </a>  PetscSFLink link;
<a name="line193">193: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> rank;

<a name="line195">195: </a>  PetscSFBcastBegin_Gatherv(sf, unit, rootmtype, rootdata, leafmtype, leafdata, MPI_REPLACE);
<a name="line196">196: </a>  PetscSFLinkGetInUse(sf, unit, rootdata, leafdata, <a href="../../../../../../docs/manualpages/Sys/PetscCopyMode.html">PETSC_OWN_POINTER</a>, &amp;link);
<a name="line197">197: </a>  PetscSFLinkFinishCommunication(sf, link, PETSCSF_../../../../../..2LEAF);
<a name="line198">198: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(<a href="../../../../../../docs/manualpages/Sys/PetscObjectComm.html">PetscObjectComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf), &amp;rank);
<a name="line199">199: </a>  <font color="#4169E1">if</font> (rank == 0 &amp;&amp; PetscMemTypeDevice(leafmtype) &amp;&amp; !sf-&gt;use_gpu_aware_mpi) (*link-&gt;Memcpy)(link, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PETSC_MEMTYPE_DEVICE</a>, leafdata, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PETSC_MEMTYPE_HOST</a>, link-&gt;leafbuf[<a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PETSC_MEMTYPE_HOST</a>], sf-&gt;leafbuflen[PETSCSF_REMOTE] * link-&gt;unitbytes);
<a name="line200">200: </a>  PetscSFLinkReclaim(sf, &amp;link);
<a name="line201">201: </a>  <font color="#4169E1">return</font> 0;
<a name="line202">202: </a>}

<a name="line204">204: </a><font color="#B22222">/* This routine is very tricky (I believe it is rarely used with this kind of graph so just provide a simple but not-optimal implementation).</font>

<a name="line206">206: </a><font color="#B22222">   Suppose we have three ranks. Rank 0 has a root with value 1. Rank 0,1,2 has a leaf with value 2,3,4 respectively. The leaves are connected</font>
<a name="line207">207: </a><font color="#B22222">   to the root on rank 0. Suppose op=MPI_SUM and rank 0,1,2 gets root state in their rank order. By definition of this routine, rank 0 sees 1</font>
<a name="line208">208: </a><font color="#B22222">   in root, fetches it into its leafupate, then updates root to 1 + 2 = 3; rank 1 sees 3 in root, fetches it into its leafupate, then updates</font>
<a name="line209">209: </a><font color="#B22222">   root to 3 + 3 = 6; rank 2 sees 6 in root, fetches it into its leafupdate, then updates root to 6 + 4 = 10.  At the end, leafupdate on rank</font>
<a name="line210">210: </a><font color="#B22222">   0,1,2 is 1,3,6 respectively. root is 10.</font>

<a name="line212">212: </a><font color="#B22222">   We use a simpler implementation. From the same initial state, we copy leafdata to leafupdate</font>
<a name="line213">213: </a><font color="#B22222">             rank-0   rank-1    rank-2</font>
<a name="line214">214: </a><font color="#B22222">        Root     1</font>
<a name="line215">215: </a><font color="#B22222">        Leaf     2       3         4</font>
<a name="line216">216: </a><font color="#B22222">     Leafupdate  2       3         4</font>

<a name="line218">218: </a><font color="#B22222">   Do <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Exscan.html#MPI_Exscan">MPI_Exscan</a> on leafupdate,</font>
<a name="line219">219: </a><font color="#B22222">             rank-0   rank-1    rank-2</font>
<a name="line220">220: </a><font color="#B22222">        Root     1</font>
<a name="line221">221: </a><font color="#B22222">        Leaf     2       3         4</font>
<a name="line222">222: </a><font color="#B22222">     Leafupdate  2       2         5</font>

<a name="line224">224: </a><font color="#B22222">   BcastAndOp from root to leafupdate,</font>
<a name="line225">225: </a><font color="#B22222">             rank-0   rank-1    rank-2</font>
<a name="line226">226: </a><font color="#B22222">        Root     1</font>
<a name="line227">227: </a><font color="#B22222">        Leaf     2       3         4</font>
<a name="line228">228: </a><font color="#B22222">     Leafupdate  3       3         6</font>

<a name="line230">230: </a><font color="#B22222">   Copy root to leafupdate on rank-0</font>
<a name="line231">231: </a><font color="#B22222">             rank-0   rank-1    rank-2</font>
<a name="line232">232: </a><font color="#B22222">        Root     1</font>
<a name="line233">233: </a><font color="#B22222">        Leaf     2       3         4</font>
<a name="line234">234: </a><font color="#B22222">     Leafupdate  1       3         6</font>

<a name="line236">236: </a><font color="#B22222">   Reduce from leaf to root,</font>
<a name="line237">237: </a><font color="#B22222">             rank-0   rank-1    rank-2</font>
<a name="line238">238: </a><font color="#B22222">        Root     10</font>
<a name="line239">239: </a><font color="#B22222">        Leaf     2       3         4</font>
<a name="line240">240: </a><font color="#B22222">     Leafupdate  1       3         6</font>
<a name="line241">241: </a><font color="#B22222">*/</font>
<a name="line242">242: </a><strong><font color="#4169E1"><a name="PetscSFFetchAndOpBegin_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFFetchAndOpBegin_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> rootmtype, void *rootdata, <a href="../../../../../../docs/manualpages/Sys/PetscMemType.html">PetscMemType</a> leafmtype, const void *leafdata, void *leafupdate, MPI_Op op)</font></strong>
<a name="line243">243: </a>{
<a name="line244">244: </a>  PetscSFLink link;
<a name="line245">245: </a>  <a href="../../../../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>    comm;
<a name="line246">246: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count;

<a name="line248">248: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscObjectGetComm.html">PetscObjectGetComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, &amp;comm);
<a name="line250">250: </a>  <font color="#B22222">/* Copy leafdata to leafupdate */</font>
<a name="line251">251: </a>  PetscSFLinkCreate(sf, unit, rootmtype, rootdata, leafmtype, leafdata, op, PETSCSF_FETCH, &amp;link);
<a name="line252">252: </a>  PetscSFLinkPackLeafData(sf, link, PETSCSF_REMOTE, leafdata); <font color="#B22222">/* Sync the device */</font>
<a name="line253">253: </a>  (*link-&gt;Memcpy)(link, leafmtype, leafupdate, leafmtype, leafdata, sf-&gt;nleaves * link-&gt;unitbytes);
<a name="line254">254: </a>  PetscSFLinkGetInUse(sf, unit, rootdata, leafdata, <a href="../../../../../../docs/manualpages/Sys/PetscCopyMode.html">PETSC_OWN_POINTER</a>, &amp;link);

<a name="line256">256: </a>  <font color="#B22222">/* Exscan on leafupdate and then BcastAndOp rootdata to leafupdate */</font>
<a name="line257">257: </a>  <font color="#4169E1">if</font> (op == MPI_REPLACE) {
<a name="line258">258: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> size, rank, prev, next;
<a name="line259">259: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line260">260: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line261">261: </a>    prev = rank ? rank - 1 : MPI_PROC_NULL;
<a name="line262">262: </a>    next = (rank &lt; size - 1) ? rank + 1 : MPI_PROC_NULL;
<a name="line263">263: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(sf-&gt;nleaves, &amp;count);
<a name="line264">264: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Sendrecv_replace.html#MPI_Sendrecv_replace">MPI_Sendrecv_replace</a>(leafupdate, count, unit, next, link-&gt;tag, prev, link-&gt;tag, comm, MPI_STATUSES_IGNORE);
<a name="line265">265: </a>  } <font color="#4169E1">else</font> {
<a name="line266">266: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(sf-&gt;nleaves * link-&gt;bs, &amp;count);
<a name="line267">267: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Exscan.html#MPI_Exscan">MPI_Exscan</a>(MPI_IN_PLACE, leafupdate, count, link-&gt;basicunit, op, comm);
<a name="line268">268: </a>  }
<a name="line269">269: </a>  PetscSFLinkReclaim(sf, &amp;link);
<a name="line270">270: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFBcastBegin.html">PetscSFBcastBegin</a>(sf, unit, rootdata, leafupdate, op);
<a name="line271">271: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFBcastEnd.html">PetscSFBcastEnd</a>(sf, unit, rootdata, leafupdate, op);

<a name="line273">273: </a>  <font color="#B22222">/* Bcast roots to rank 0's leafupdate */</font>
<a name="line274">274: </a>  PetscSFBcastToZero_Private(sf, unit, rootdata, leafupdate); <font color="#B22222">/* Using this line makes Allgather SFs able to inherit this routine */</font>

<a name="line276">276: </a>  <font color="#B22222">/* Reduce leafdata to rootdata */</font>
<a name="line277">277: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFReduceBegin.html">PetscSFReduceBegin</a>(sf, unit, leafdata, rootdata, op);
<a name="line278">278: </a>  <font color="#4169E1">return</font> 0;
<a name="line279">279: </a>}

<a name="line281">281: </a><strong><font color="#4169E1"><a name="PetscSFFetchAndOpEnd_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFFetchAndOpEnd_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, MPI_Datatype unit, void *rootdata, const void *leafdata, void *leafupdate, MPI_Op op)</font></strong>
<a name="line282">282: </a>{
<a name="line283">283: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFReduceEnd.html">PetscSFReduceEnd</a>(sf, unit, leafdata, rootdata, op);
<a name="line284">284: </a>  <font color="#4169E1">return</font> 0;
<a name="line285">285: </a>}

<a name="line287">287: </a><font color="#B22222">/* Get root ranks accessing my leaves */</font>
<a name="line288">288: </a><strong><font color="#4169E1"><a name="PetscSFGetRootRanks_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFGetRootRanks_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *nranks, const <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **ranks, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **roffset, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **rmine, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **rremote)</font></strong>
<a name="line289">289: </a>{
<a name="line290">290: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>        i, j, k, size;
<a name="line291">291: </a>  const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *range;

<a name="line293">293: </a>  <font color="#B22222">/* Lazily construct these large arrays if users really need them for this type of SF. Very likely, they do not */</font>
<a name="line294">294: </a>  <font color="#4169E1">if</font> (sf-&gt;nranks &amp;&amp; !sf-&gt;ranks) { <font color="#B22222">/* On rank!=0, sf-&gt;nranks=0. The sf-&gt;nranks test makes this routine also works for sfgatherv */</font>
<a name="line295">295: </a>    size = sf-&gt;nranks;
<a name="line296">296: </a>    <a href="../../../../../../docs/manualpages/IS/PetscLayoutGetRanges.html">PetscLayoutGetRanges</a>(sf-&gt;map, &amp;range);
<a name="line297">297: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscMalloc4.html">PetscMalloc4</a>(size, &amp;sf-&gt;ranks, size + 1, &amp;sf-&gt;roffset, sf-&gt;nleaves, &amp;sf-&gt;rmine, sf-&gt;nleaves, &amp;sf-&gt;rremote);
<a name="line298">298: </a>    <font color="#4169E1">for</font> (i = 0; i &lt; size; i++) sf-&gt;ranks[i] = i;
<a name="line299">299: </a>    <a href="../../../../../../docs/manualpages/Sys/PetscArraycpy.html">PetscArraycpy</a>(sf-&gt;roffset, range, size + 1);
<a name="line300">300: </a>    <font color="#4169E1">for</font> (i = 0; i &lt; sf-&gt;nleaves; i++) sf-&gt;rmine[i] = i; <font color="#B22222">/*rmine are never NULL even for contiguous leaves */</font>
<a name="line301">301: </a>    <font color="#4169E1">for</font> (i = 0; i &lt; size; i++) {
<a name="line302">302: </a>      <font color="#4169E1">for</font> (j = range[i], k = 0; j &lt; range[i + 1]; j++, k++) sf-&gt;rremote[j] = k;
<a name="line303">303: </a>    }
<a name="line304">304: </a>  }

<a name="line306">306: </a>  <font color="#4169E1">if</font> (nranks) *nranks = sf-&gt;nranks;
<a name="line307">307: </a>  <font color="#4169E1">if</font> (ranks) *ranks = sf-&gt;ranks;
<a name="line308">308: </a>  <font color="#4169E1">if</font> (roffset) *roffset = sf-&gt;roffset;
<a name="line309">309: </a>  <font color="#4169E1">if</font> (rmine) *rmine = sf-&gt;rmine;
<a name="line310">310: </a>  <font color="#4169E1">if</font> (rremote) *rremote = sf-&gt;rremote;
<a name="line311">311: </a>  <font color="#4169E1">return</font> 0;
<a name="line312">312: </a>}

<a name="line314">314: </a><font color="#B22222">/* Get leaf ranks accessing my roots */</font>
<a name="line315">315: </a><strong><font color="#4169E1"><a name="PetscSFGetLeafRanks_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFGetLeafRanks_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> *niranks, const <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **iranks, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **ioffset, const <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a> **irootloc)</font></strong>
<a name="line316">316: </a>{
<a name="line317">317: </a>  PetscSF_Allgatherv *dat = (PetscSF_Allgatherv *)sf-&gt;data;
<a name="line318">318: </a>  <a href="../../../../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>            comm;
<a name="line319">319: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>         size, rank;
<a name="line320">320: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>            i, j;

<a name="line322">322: </a>  <font color="#B22222">/* Lazily construct these large arrays if users really need them for this type of SF. Very likely, they do not */</font>
<a name="line323">323: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscObjectGetComm.html">PetscObjectGetComm</a>((<a href="../../../../../../docs/manualpages/Sys/PetscObject.html">PetscObject</a>)sf, &amp;comm);
<a name="line324">324: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line325">325: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line326">326: </a>  <font color="#4169E1">if</font> (niranks) *niranks = size;

<a name="line328">328: </a>  <font color="#B22222">/* PetscSF_Basic has distinguished incoming ranks. Here we do not need that. But we must put self as the first and</font>
<a name="line329">329: </a><font color="#B22222">     sort other ranks. See comments in PetscSFSetUp_Basic about MatGetBrowsOfAoCols_MPIAIJ on why.</font>
<a name="line330">330: </a><font color="#B22222">   */</font>
<a name="line331">331: </a>  <font color="#4169E1">if</font> (iranks) {
<a name="line332">332: </a>    <font color="#4169E1">if</font> (!dat-&gt;iranks) {
<a name="line333">333: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(size, &amp;dat-&gt;iranks);
<a name="line334">334: </a>      dat-&gt;iranks[0] = rank;
<a name="line335">335: </a>      <font color="#4169E1">for</font> (i = 0, j = 1; i &lt; size; i++) {
<a name="line336">336: </a>        <font color="#4169E1">if</font> (i == rank) <font color="#4169E1">continue</font>;
<a name="line337">337: </a>        dat-&gt;iranks[j++] = i;
<a name="line338">338: </a>      }
<a name="line339">339: </a>    }
<a name="line340">340: </a>    *iranks = dat-&gt;iranks; <font color="#B22222">/* dat-&gt;iranks was init'ed to NULL by <a href="../../../../../../docs/manualpages/Sys/PetscNew.html">PetscNew</a> */</font>
<a name="line341">341: </a>  }

<a name="line343">343: </a>  <font color="#4169E1">if</font> (ioffset) {
<a name="line344">344: </a>    <font color="#4169E1">if</font> (!dat-&gt;ioffset) {
<a name="line345">345: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(size + 1, &amp;dat-&gt;ioffset);
<a name="line346">346: </a>      <font color="#4169E1">for</font> (i = 0; i &lt;= size; i++) dat-&gt;ioffset[i] = i * sf-&gt;nroots;
<a name="line347">347: </a>    }
<a name="line348">348: </a>    *ioffset = dat-&gt;ioffset;
<a name="line349">349: </a>  }

<a name="line351">351: </a>  <font color="#4169E1">if</font> (irootloc) {
<a name="line352">352: </a>    <font color="#4169E1">if</font> (!dat-&gt;irootloc) {
<a name="line353">353: </a>      <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(sf-&gt;nleaves, &amp;dat-&gt;irootloc);
<a name="line354">354: </a>      <font color="#4169E1">for</font> (i = 0; i &lt; size; i++) {
<a name="line355">355: </a>        <font color="#4169E1">for</font> (j = 0; j &lt; sf-&gt;nroots; j++) dat-&gt;irootloc[i * sf-&gt;nroots + j] = j;
<a name="line356">356: </a>      }
<a name="line357">357: </a>    }
<a name="line358">358: </a>    *irootloc = dat-&gt;irootloc;
<a name="line359">359: </a>  }
<a name="line360">360: </a>  <font color="#4169E1">return</font> 0;
<a name="line361">361: </a>}

<a name="line363">363: </a><strong><font color="#4169E1"><a name="PetscSFCreateLocalSF_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFCreateLocalSF_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf, <a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> *out)</font></strong>
<a name="line364">364: </a>{
<a name="line365">365: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscInt.html">PetscInt</a>     i, nroots, nleaves, rstart, *ilocal;
<a name="line366">366: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFNode.html">PetscSFNode</a> *iremote;
<a name="line367">367: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a>      lsf;

<a name="line369">369: </a>  nleaves = sf-&gt;nleaves ? sf-&gt;nroots : 0; <font color="#B22222">/* sf-&gt;nleaves can be zero with SFGather(v) */</font>
<a name="line370">370: </a>  nroots  = nleaves;
<a name="line371">371: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nleaves, &amp;ilocal);
<a name="line372">372: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nleaves, &amp;iremote);
<a name="line373">373: </a>  <a href="../../../../../../docs/manualpages/IS/PetscLayoutGetRange.html">PetscLayoutGetRange</a>(sf-&gt;map, &amp;rstart, NULL);

<a name="line375">375: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nleaves; i++) {
<a name="line376">376: </a>    ilocal[i]        = rstart + i; <font color="#B22222">/* lsf does not change leave indices */</font>
<a name="line377">377: </a>    iremote[i].rank  = 0;          <font color="#B22222">/* rank in <a href="../../../../../../docs/manualpages/Sys/PETSC_COMM_SELF.html">PETSC_COMM_SELF</a> */</font>
<a name="line378">378: </a>    iremote[i].index = i;          <font color="#B22222">/* root index */</font>
<a name="line379">379: </a>  }

<a name="line381">381: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFCreate.html">PetscSFCreate</a>(<a href="../../../../../../docs/manualpages/Sys/PETSC_COMM_SELF.html">PETSC_COMM_SELF</a>, &amp;lsf);
<a name="line382">382: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFSetGraph.html">PetscSFSetGraph</a>(lsf, nroots, nleaves, ilocal, <a href="../../../../../../docs/manualpages/Sys/PetscCopyMode.html">PETSC_OWN_POINTER</a>, iremote, <a href="../../../../../../docs/manualpages/Sys/PetscCopyMode.html">PETSC_OWN_POINTER</a>);
<a name="line383">383: </a>  <a href="../../../../../../docs/manualpages/PetscSF/PetscSFSetUp.html">PetscSFSetUp</a>(lsf);
<a name="line384">384: </a>  *out = lsf;
<a name="line385">385: </a>  <font color="#4169E1">return</font> 0;
<a name="line386">386: </a>}

<a name="line388">388: </a><strong><font color="#4169E1"><a name="PetscSFCreate_Allgatherv"></a>PETSC_INTERN <a href="../../../../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscSFCreate_Allgatherv(<a href="../../../../../../docs/manualpages/PetscSF/PetscSF.html">PetscSF</a> sf)</font></strong>
<a name="line389">389: </a>{
<a name="line390">390: </a>  PetscSF_Allgatherv *dat = (PetscSF_Allgatherv *)sf-&gt;data;

<a name="line392">392: </a>  sf-&gt;ops-&gt;BcastEnd  = PetscSFBcastEnd_Basic;
<a name="line393">393: </a>  sf-&gt;ops-&gt;ReduceEnd = PetscSFReduceEnd_Allgatherv;

<a name="line395">395: </a>  sf-&gt;ops-&gt;SetUp           = PetscSFSetUp_Allgatherv;
<a name="line396">396: </a>  sf-&gt;ops-&gt;Reset           = PetscSFReset_Allgatherv;
<a name="line397">397: </a>  sf-&gt;ops-&gt;Destroy         = PetscSFDestroy_Allgatherv;
<a name="line398">398: </a>  sf-&gt;ops-&gt;GetRootRanks    = PetscSFGetRootRanks_Allgatherv;
<a name="line399">399: </a>  sf-&gt;ops-&gt;GetLeafRanks    = PetscSFGetLeafRanks_Allgatherv;
<a name="line400">400: </a>  sf-&gt;ops-&gt;GetGraph        = PetscSFGetGraph_Allgatherv;
<a name="line401">401: </a>  sf-&gt;ops-&gt;BcastBegin      = PetscSFBcastBegin_Allgatherv;
<a name="line402">402: </a>  sf-&gt;ops-&gt;ReduceBegin     = PetscSFReduceBegin_Allgatherv;
<a name="line403">403: </a>  sf-&gt;ops-&gt;FetchAndOpBegin = PetscSFFetchAndOpBegin_Allgatherv;
<a name="line404">404: </a>  sf-&gt;ops-&gt;FetchAndOpEnd   = PetscSFFetchAndOpEnd_Allgatherv;
<a name="line405">405: </a>  sf-&gt;ops-&gt;CreateLocalSF   = PetscSFCreateLocalSF_Allgatherv;
<a name="line406">406: </a>  sf-&gt;ops-&gt;BcastToZero     = PetscSFBcastToZero_Allgatherv;

<a name="line408">408: </a>  <a href="../../../../../../docs/manualpages/Sys/PetscNew.html">PetscNew</a>(&amp;dat);
<a name="line409">409: </a>  dat-&gt;bcast_root = -1;
<a name="line410">410: </a>  sf-&gt;data        = (void *)dat;
<a name="line411">411: </a>  <font color="#4169E1">return</font> 0;
<a name="line412">412: </a>}
</pre>
</body>

</html>
