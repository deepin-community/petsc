<center><a href="https://gitlab.com/petsc/petsc/-/blob/c7d19d7b3f2d9e6411c648820d1207320e4154c7/src/sys/utils/mpits.c">Actual source code: mpits.c</a></center><br>

<html>
<head>
<title></title>
<meta name="generator" content="c2html 0.9.4">
<meta name="date" content="2023-03-30T15:47:02+00:00">
</head>

<body bgcolor="#FFFFFF">
<pre width="80">
<a name="line1">  1: </a>#include <A href="../../../include/petscsys.h.html">&lt;petscsys.h&gt;</A>
<a name="line2">  2: </a>#include <A href="../../../include/petsc/private/petscimpl.h.html">&lt;petsc/private/petscimpl.h&gt;</A>

<a name="line4">  4: </a><a href="../../../docs/manualpages/Sys/PetscLogEvent.html">PetscLogEvent</a> PETSC_BuildTwoSided;
<a name="line5">  5: </a><a href="../../../docs/manualpages/Sys/PetscLogEvent.html">PetscLogEvent</a> PETSC_BuildTwoSidedF;

<a name="line7">  7: </a>const char *const PetscBuildTwoSidedTypes[] = {<font color="#666666">"ALLREDUCE"</font>, <font color="#666666">"IBARRIER"</font>, <font color="#666666">"REDSCATTER"</font>, <font color="#666666">"<a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a>"</font>, <font color="#666666">"PETSC_BUILDTWOSIDED_"</font>, NULL};

<a name="line9">  9: </a>static <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a> _twosided_type = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_NOTSET</a>;

<a name="line11"> 11: </a><font color="#B22222">/*@</font>
<a name="line12"> 12: </a><font color="#B22222">   <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedSetType.html">PetscCommBuildTwoSidedSetType</a> - set algorithm to use when building two-sided communication</font>

<a name="line14"> 14: </a><font color="#B22222">   Logically Collective</font>

<a name="line16"> 16: </a><font color="#B22222">   Input Parameters:</font>
<a name="line17"> 17: </a><font color="#B22222">+  comm - `<a href="../../../docs/manualpages/Sys/PETSC_COMM_WORLD.html">PETSC_COMM_WORLD</a>`</font>
<a name="line18"> 18: </a><font color="#B22222">-  twosided - algorithm to use in subsequent calls to `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`</font>

<a name="line20"> 20: </a><font color="#B22222">   Level: developer</font>

<a name="line22"> 22: </a><font color="#B22222">   Note:</font>
<a name="line23"> 23: </a><font color="#B22222">   This option is currently global, but could be made per-communicator.</font>

<a name="line25"> 25: </a><font color="#B22222">.seealso: `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`, `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedGetType.html">PetscCommBuildTwoSidedGetType</a>()`, `<a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a>`</font>
<a name="line26"> 26: </a><font color="#B22222">@*/</font>
<a name="line27"> 27: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedSetType"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedSetType.html">PetscCommBuildTwoSidedSetType</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a> twosided)</font></strong>
<a name="line28"> 28: </a>{
<a name="line30"> 30: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> b1[2], b2[2];
<a name="line31"> 31: </a>    b1[0] = -(<a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>)twosided;
<a name="line32"> 32: </a>    b1[1] = (<a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>)twosided;
<a name="line33"> 33: </a>    <a href="../../../docs/manualpages/Sys/MPIU_Allreduce.html">MPIU_Allreduce</a>(b1, b2, 2, MPI_INT, MPI_MAX, comm);
<a name="line35"> 35: </a>  }
<a name="line36"> 36: </a>  _twosided_type = twosided;
<a name="line37"> 37: </a>  <font color="#4169E1">return</font> 0;
<a name="line38"> 38: </a>}

<a name="line40"> 40: </a><font color="#B22222">/*@</font>
<a name="line41"> 41: </a><font color="#B22222">   <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedGetType.html">PetscCommBuildTwoSidedGetType</a> - get algorithm used when building two-sided communication</font>

<a name="line43"> 43: </a><font color="#B22222">   Logically Collective</font>

<a name="line45"> 45: </a><font color="#B22222">   Output Parameters:</font>
<a name="line46"> 46: </a><font color="#B22222">+  comm - communicator on which to query algorithm</font>
<a name="line47"> 47: </a><font color="#B22222">-  twosided - algorithm to use for `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`</font>

<a name="line49"> 49: </a><font color="#B22222">   Level: developer</font>

<a name="line51"> 51: </a><font color="#B22222">.seealso: `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`, `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedSetType.html">PetscCommBuildTwoSidedSetType</a>()`, `<a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a>`</font>
<a name="line52"> 52: </a><font color="#B22222">@*/</font>
<a name="line53"> 53: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedGetType"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedGetType.html">PetscCommBuildTwoSidedGetType</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a> *twosided)</font></strong>
<a name="line54"> 54: </a>{
<a name="line55"> 55: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> size;

<a name="line57"> 57: </a>  *twosided = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_NOTSET</a>;
<a name="line58"> 58: </a>  <font color="#4169E1">if</font> (_twosided_type == <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_NOTSET</a>) {
<a name="line59"> 59: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line60"> 60: </a>    _twosided_type = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_ALLREDUCE</a>; <font color="#B22222">/* default for small comms, see https://gitlab.com/petsc/petsc/-/merge_requests/2611 */</font>
<a name="line61"> 61: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_NONBLOCKING_COLLECTIVES)</font>
<a name="line62"> 62: </a>    <font color="#4169E1">if</font> (size &gt; 1024) _twosided_type = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_IBARRIER</a>;
<a name="line63"> 63: </a><font color="#A020F0">#endif</font>
<a name="line64"> 64: </a>    <a href="../../../docs/manualpages/Sys/PetscOptionsGetEnum.html">PetscOptionsGetEnum</a>(NULL, NULL, <font color="#666666">"-build_twosided"</font>, PetscBuildTwoSidedTypes, (<a href="../../../docs/manualpages/Sys/PetscEnum.html">PetscEnum</a> *)&amp;_twosided_type, NULL);
<a name="line65"> 65: </a>  }
<a name="line66"> 66: </a>  *twosided = _twosided_type;
<a name="line67"> 67: </a>  <font color="#4169E1">return</font> 0;
<a name="line68"> 68: </a>}

<a name="line70"> 70: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_NONBLOCKING_COLLECTIVES)</font>
<a name="line71"> 71: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSided_Ibarrier"></a>static <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscCommBuildTwoSided_Ibarrier(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata)</font></strong>
<a name="line72"> 72: </a>{
<a name="line73"> 73: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>    nrecvs, tag, done, i;
<a name="line74"> 74: </a>  MPI_Aint       lb, unitbytes;
<a name="line75"> 75: </a>  char          *tdata;
<a name="line76"> 76: </a>  MPI_Request   *sendreqs, barrier;
<a name="line77"> 77: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBuffer.html">PetscSegBuffer</a> segrank, segdata;
<a name="line78"> 78: </a>  <a href="../../../docs/manualpages/Sys/PetscBool.html">PetscBool</a>      barrier_started;

<a name="line80"> 80: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDuplicate.html">PetscCommDuplicate</a>(comm, &amp;comm, &amp;tag);
<a name="line81"> 81: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Type_get_extent.html#MPI_Type_get_extent">MPI_Type_get_extent</a>(dtype, &amp;lb, &amp;unitbytes);
<a name="line83"> 83: </a>  tdata = (char *)todata;
<a name="line84"> 84: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nto, &amp;sendreqs);
<a name="line85"> 85: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Issend.html#MPI_Issend">MPI_Issend</a>((void *)(tdata + count * unitbytes * i), count, dtype, toranks[i], tag, comm, sendreqs + i);
<a name="line86"> 86: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferCreate.html">PetscSegBufferCreate</a>(<font color="#4169E1">sizeof</font>(<a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>), 4, &amp;segrank);
<a name="line87"> 87: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferCreate.html">PetscSegBufferCreate</a>(unitbytes, 4 * count, &amp;segdata);

<a name="line89"> 89: </a>  nrecvs  = 0;
<a name="line90"> 90: </a>  barrier = MPI_REQUEST_NULL;
<a name="line91"> 91: </a>  <font color="#B22222">/* MPICH-3.2 sometimes does not create a request in some "optimized" cases.  This is arguably a standard violation,</font>
<a name="line92"> 92: </a><font color="#B22222">   * but we need to work around it. */</font>
<a name="line93"> 93: </a>  barrier_started = <a href="../../../docs/manualpages/Sys/PETSC_FALSE.html">PETSC_FALSE</a>;
<a name="line94"> 94: </a>  <font color="#4169E1">for</font> (done = 0; !done;) {
<a name="line95"> 95: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> flag;
<a name="line96"> 96: </a>    MPI_Status  status;
<a name="line97"> 97: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Iprobe.html#MPI_Iprobe">MPI_Iprobe</a>(MPI_ANY_SOURCE, tag, comm, &amp;flag, &amp;status);
<a name="line98"> 98: </a>    <font color="#4169E1">if</font> (flag) { <font color="#B22222">/* incoming message */</font>
<a name="line99"> 99: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *recvrank;
<a name="line100">100: </a>      void        *buf;
<a name="line101">101: </a>      <a href="../../../docs/manualpages/Sys/PetscSegBufferGet.html">PetscSegBufferGet</a>(segrank, 1, &amp;recvrank);
<a name="line102">102: </a>      <a href="../../../docs/manualpages/Sys/PetscSegBufferGet.html">PetscSegBufferGet</a>(segdata, count, &amp;buf);
<a name="line103">103: </a>      *recvrank = status.MPI_SOURCE;
<a name="line104">104: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Recv.html#MPI_Recv">MPI_Recv</a>(buf, count, dtype, status.MPI_SOURCE, tag, comm, MPI_STATUS_IGNORE);
<a name="line105">105: </a>      nrecvs++;
<a name="line106">106: </a>    }
<a name="line107">107: </a>    <font color="#4169E1">if</font> (!barrier_started) {
<a name="line108">108: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> sent, nsends;
<a name="line109">109: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(nto, &amp;nsends);
<a name="line110">110: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Testall.html#MPI_Testall">MPI_Testall</a>(nsends, sendreqs, &amp;sent, MPI_STATUSES_IGNORE);
<a name="line111">111: </a>      <font color="#4169E1">if</font> (sent) {
<a name="line112">112: </a>        <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a>(comm, &amp;barrier);
<a name="line113">113: </a>        barrier_started = <a href="../../../docs/manualpages/Sys/PETSC_TRUE.html">PETSC_TRUE</a>;
<a name="line114">114: </a>        <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(sendreqs);
<a name="line115">115: </a>      }
<a name="line116">116: </a>    } <font color="#4169E1">else</font> {
<a name="line117">117: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Test.html#MPI_Test">MPI_Test</a>(&amp;barrier, &amp;done, MPI_STATUS_IGNORE);
<a name="line118">118: </a>    }
<a name="line119">119: </a>  }
<a name="line120">120: </a>  *nfrom = nrecvs;
<a name="line121">121: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferExtractAlloc.html">PetscSegBufferExtractAlloc</a>(segrank, fromranks);
<a name="line122">122: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferDestroy.html">PetscSegBufferDestroy</a>(&amp;segrank);
<a name="line123">123: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferExtractAlloc.html">PetscSegBufferExtractAlloc</a>(segdata, fromdata);
<a name="line124">124: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferDestroy.html">PetscSegBufferDestroy</a>(&amp;segdata);
<a name="line125">125: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDestroy.html">PetscCommDestroy</a>(&amp;comm);
<a name="line126">126: </a>  <font color="#4169E1">return</font> 0;
<a name="line127">127: </a>}
<a name="line128">128: </a><font color="#A020F0">#endif</font>

<a name="line130">130: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSided_Allreduce"></a>static <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscCommBuildTwoSided_Allreduce(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata)</font></strong>
<a name="line131">131: </a>{
<a name="line132">132: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>       size, rank, *iflags, nrecvs, tag, *franks, i, flg;
<a name="line133">133: </a>  MPI_Aint          lb, unitbytes;
<a name="line134">134: </a>  char             *tdata, *fdata;
<a name="line135">135: </a>  MPI_Request      *reqs, *sendreqs;
<a name="line136">136: </a>  MPI_Status       *statuses;
<a name="line137">137: </a>  PetscCommCounter *counter;

<a name="line139">139: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line140">140: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_rank.html#MPI_Comm_rank">MPI_Comm_rank</a>(comm, &amp;rank);
<a name="line141">141: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDuplicate.html">PetscCommDuplicate</a>(comm, &amp;comm, &amp;tag);
<a name="line142">142: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_get_attr.html#MPI_Comm_get_attr">MPI_Comm_get_attr</a>(comm, Petsc_Counter_keyval, &amp;counter, &amp;flg);
<a name="line144">144: </a>  <font color="#4169E1">if</font> (!counter-&gt;iflags) {
<a name="line145">145: </a>    <a href="../../../docs/manualpages/Sys/PetscCalloc1.html">PetscCalloc1</a>(size, &amp;counter-&gt;iflags);
<a name="line146">146: </a>    iflags = counter-&gt;iflags;
<a name="line147">147: </a>  } <font color="#4169E1">else</font> {
<a name="line148">148: </a>    iflags = counter-&gt;iflags;
<a name="line149">149: </a>    <a href="../../../docs/manualpages/Sys/PetscArrayzero.html">PetscArrayzero</a>(iflags, size);
<a name="line150">150: </a>  }
<a name="line151">151: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) iflags[toranks[i]] = 1;
<a name="line152">152: </a>  <a href="../../../docs/manualpages/Sys/MPIU_Allreduce.html">MPIU_Allreduce</a>(MPI_IN_PLACE, iflags, size, MPI_INT, MPI_SUM, comm);
<a name="line153">153: </a>  nrecvs = iflags[rank];
<a name="line154">154: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Type_get_extent.html#MPI_Type_get_extent">MPI_Type_get_extent</a>(dtype, &amp;lb, &amp;unitbytes);
<a name="line156">156: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc.html">PetscMalloc</a>(nrecvs * count * unitbytes, &amp;fdata);
<a name="line157">157: </a>  tdata = (char *)todata;
<a name="line158">158: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc2.html">PetscMalloc2</a>(nto + nrecvs, &amp;reqs, nto + nrecvs, &amp;statuses);
<a name="line159">159: </a>  sendreqs = reqs + nrecvs;
<a name="line160">160: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nrecvs; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>((void *)(fdata + count * unitbytes * i), count, dtype, MPI_ANY_SOURCE, tag, comm, reqs + i);
<a name="line161">161: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</a>((void *)(tdata + count * unitbytes * i), count, dtype, toranks[i], tag, comm, sendreqs + i);
<a name="line162">162: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(nto + nrecvs, reqs, statuses);
<a name="line163">163: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nrecvs, &amp;franks);
<a name="line164">164: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nrecvs; i++) franks[i] = statuses[i].MPI_SOURCE;
<a name="line165">165: </a>  <a href="../../../docs/manualpages/Sys/PetscFree2.html">PetscFree2</a>(reqs, statuses);
<a name="line166">166: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDestroy.html">PetscCommDestroy</a>(&amp;comm);

<a name="line168">168: </a>  *nfrom             = nrecvs;
<a name="line169">169: </a>  *fromranks         = franks;
<a name="line170">170: </a>  *(void **)fromdata = fdata;
<a name="line171">171: </a>  <font color="#4169E1">return</font> 0;
<a name="line172">172: </a>}

<a name="line174">174: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_REDUCE_SCATTER_BLOCK)</font>
<a name="line175">175: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSided_RedScatter"></a>static <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscCommBuildTwoSided_RedScatter(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata)</font></strong>
<a name="line176">176: </a>{
<a name="line177">177: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>       size, *iflags, nrecvs, tag, *franks, i, flg;
<a name="line178">178: </a>  MPI_Aint          lb, unitbytes;
<a name="line179">179: </a>  char             *tdata, *fdata;
<a name="line180">180: </a>  MPI_Request      *reqs, *sendreqs;
<a name="line181">181: </a>  MPI_Status       *statuses;
<a name="line182">182: </a>  PetscCommCounter *counter;

<a name="line184">184: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line185">185: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDuplicate.html">PetscCommDuplicate</a>(comm, &amp;comm, &amp;tag);
<a name="line186">186: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_get_attr.html#MPI_Comm_get_attr">MPI_Comm_get_attr</a>(comm, Petsc_Counter_keyval, &amp;counter, &amp;flg);
<a name="line188">188: </a>  <font color="#4169E1">if</font> (!counter-&gt;iflags) {
<a name="line189">189: </a>    <a href="../../../docs/manualpages/Sys/PetscCalloc1.html">PetscCalloc1</a>(size, &amp;counter-&gt;iflags);
<a name="line190">190: </a>    iflags = counter-&gt;iflags;
<a name="line191">191: </a>  } <font color="#4169E1">else</font> {
<a name="line192">192: </a>    iflags = counter-&gt;iflags;
<a name="line193">193: </a>    <a href="../../../docs/manualpages/Sys/PetscArrayzero.html">PetscArrayzero</a>(iflags, size);
<a name="line194">194: </a>  }
<a name="line195">195: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) iflags[toranks[i]] = 1;
<a name="line196">196: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Reduce_scatter_block.html#MPI_Reduce_scatter_block">MPI_Reduce_scatter_block</a>(iflags, &amp;nrecvs, 1, MPI_INT, MPI_SUM, comm);
<a name="line197">197: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Type_get_extent.html#MPI_Type_get_extent">MPI_Type_get_extent</a>(dtype, &amp;lb, &amp;unitbytes);
<a name="line199">199: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc.html">PetscMalloc</a>(nrecvs * count * unitbytes, &amp;fdata);
<a name="line200">200: </a>  tdata = (char *)todata;
<a name="line201">201: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc2.html">PetscMalloc2</a>(nto + nrecvs, &amp;reqs, nto + nrecvs, &amp;statuses);
<a name="line202">202: </a>  sendreqs = reqs + nrecvs;
<a name="line203">203: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nrecvs; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Irecv.html#MPI_Irecv">MPI_Irecv</a>((void *)(fdata + count * unitbytes * i), count, dtype, MPI_ANY_SOURCE, tag, comm, reqs + i);
<a name="line204">204: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Isend.html#MPI_Isend">MPI_Isend</a>((void *)(tdata + count * unitbytes * i), count, dtype, toranks[i], tag, comm, sendreqs + i);
<a name="line205">205: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(nto + nrecvs, reqs, statuses);
<a name="line206">206: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nrecvs, &amp;franks);
<a name="line207">207: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nrecvs; i++) franks[i] = statuses[i].MPI_SOURCE;
<a name="line208">208: </a>  <a href="../../../docs/manualpages/Sys/PetscFree2.html">PetscFree2</a>(reqs, statuses);
<a name="line209">209: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDestroy.html">PetscCommDestroy</a>(&amp;comm);

<a name="line211">211: </a>  *nfrom             = nrecvs;
<a name="line212">212: </a>  *fromranks         = franks;
<a name="line213">213: </a>  *(void **)fromdata = fdata;
<a name="line214">214: </a>  <font color="#4169E1">return</font> 0;
<a name="line215">215: </a>}
<a name="line216">216: </a><font color="#A020F0">#endif</font>

<a name="line218">218: </a><font color="#B22222">/*@C</font>
<a name="line219">219: </a><font color="#B22222">   <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a> - discovers communicating ranks given one-sided information, moving constant-sized data in the process (often message lengths)</font>

<a name="line221">221: </a><font color="#B22222">   Collective</font>

<a name="line223">223: </a><font color="#B22222">   Input Parameters:</font>
<a name="line224">224: </a><font color="#B22222">+  comm - communicator</font>
<a name="line225">225: </a><font color="#B22222">.  count - number of entries to send/receive (must match on all ranks)</font>
<a name="line226">226: </a><font color="#B22222">.  dtype - datatype to send/receive from each rank (must match on all ranks)</font>
<a name="line227">227: </a><font color="#B22222">.  nto - number of ranks to send data to</font>
<a name="line228">228: </a><font color="#B22222">.  toranks - ranks to send to (array of length nto)</font>
<a name="line229">229: </a><font color="#B22222">-  todata - data to send to each rank (packed)</font>

<a name="line231">231: </a><font color="#B22222">   Output Parameters:</font>
<a name="line232">232: </a><font color="#B22222">+  nfrom - number of ranks receiving messages from</font>
<a name="line233">233: </a><font color="#B22222">.  fromranks - ranks receiving messages from (length nfrom; caller should `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>
<a name="line234">234: </a><font color="#B22222">-  fromdata - packed data from each rank, each with count entries of type dtype (length nfrom, caller responsible for `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>

<a name="line236">236: </a><font color="#B22222">   Level: developer</font>

<a name="line238">238: </a><font color="#B22222">   Options Database Key:</font>
<a name="line239">239: </a><font color="#B22222">.  -build_twosided &lt;allreduce|ibarrier|redscatter&gt; - algorithm to set up two-sided communication. Default is allreduce for communicators with &lt;= 1024 ranks, otherwise ibarrier.</font>

<a name="line241">241: </a><font color="#B22222">   Notes:</font>
<a name="line242">242: </a><font color="#B22222">   This memory-scalable interface is an alternative to calling `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()` and</font>
<a name="line243">243: </a><font color="#B22222">   `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`, possibly with a subsequent round of communication to send other constant-size data.</font>

<a name="line245">245: </a><font color="#B22222">   Basic data types as well as contiguous types are supported, but non-contiguous (e.g., strided) types are not.</font>

<a name="line247">247: </a><font color="#B22222">   References:</font>
<a name="line248">248: </a><font color="#B22222">.  * - Hoefler, Siebert and Lumsdaine, The <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a> implementation uses the algorithm in</font>
<a name="line249">249: </a><font color="#B22222">   Scalable communication protocols for dynamic sparse data exchange, 2010.</font>

<a name="line251">251: </a><font color="#B22222">.seealso: `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()`, `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`, `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedSetType.html">PetscCommBuildTwoSidedSetType</a>()`, `PetscCommBuildTwoSidedType`</font>
<a name="line252">252: </a><font color="#B22222">@*/</font>
<a name="line253">253: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSided"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata)</font></strong>
<a name="line254">254: </a>{
<a name="line255">255: </a>  <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a> buildtype = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_NOTSET</a>;

<a name="line257">257: </a>  <a href="../../../docs/manualpages/Viewer/PetscSysInitializePackage.html">PetscSysInitializePackage</a>();
<a name="line258">258: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventSync.html">PetscLogEventSync</a>(PETSC_BuildTwoSided, comm);
<a name="line259">259: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventBegin.html">PetscLogEventBegin</a>(PETSC_BuildTwoSided, 0, 0, 0, 0);
<a name="line260">260: </a>  <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedGetType.html">PetscCommBuildTwoSidedGetType</a>(comm, &amp;buildtype);
<a name="line261">261: </a>  <font color="#4169E1">switch</font> (buildtype) {
<a name="line262">262: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_IBARRIER</a>:
<a name="line263">263: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_NONBLOCKING_COLLECTIVES)</font>
<a name="line264">264: </a>    PetscCommBuildTwoSided_Ibarrier(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata);
<a name="line265">265: </a>    <font color="#4169E1">break</font>;
<a name="line266">266: </a><font color="#A020F0">#else</font>
<a name="line267">267: </a>    <a href="../../../docs/manualpages/Sys/SETERRQ.html">SETERRQ</a>(comm, PETSC_ERR_PLIB, <font color="#666666">"MPI implementation does not provide <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a> (part of MPI-3)"</font>);
<a name="line268">268: </a><font color="#A020F0">#endif</font>
<a name="line269">269: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_ALLREDUCE</a>:
<a name="line270">270: </a>    PetscCommBuildTwoSided_Allreduce(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata);
<a name="line271">271: </a>    <font color="#4169E1">break</font>;
<a name="line272">272: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_REDSCATTER</a>:
<a name="line273">273: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_REDUCE_SCATTER_BLOCK)</font>
<a name="line274">274: </a>    PetscCommBuildTwoSided_RedScatter(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata);
<a name="line275">275: </a>    <font color="#4169E1">break</font>;
<a name="line276">276: </a><font color="#A020F0">#else</font>
<a name="line277">277: </a>    <a href="../../../docs/manualpages/Sys/SETERRQ.html">SETERRQ</a>(comm, PETSC_ERR_PLIB, <font color="#666666">"MPI implementation does not provide <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Reduce_scatter_block.html#MPI_Reduce_scatter_block">MPI_Reduce_scatter_block</a> (part of MPI-2.2)"</font>);
<a name="line278">278: </a><font color="#A020F0">#endif</font>
<a name="line279">279: </a><strong><font color="#FF0000">  default:</font></strong>
<a name="line280">280: </a>    <a href="../../../docs/manualpages/Sys/SETERRQ.html">SETERRQ</a>(comm, PETSC_ERR_PLIB, <font color="#666666">"Unknown method for building two-sided communication"</font>);
<a name="line281">281: </a>  }
<a name="line282">282: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventEnd.html">PetscLogEventEnd</a>(PETSC_BuildTwoSided, 0, 0, 0, 0);
<a name="line283">283: </a>  <font color="#4169E1">return</font> 0;
<a name="line284">284: </a>}

<a name="line286">286: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedFReq_Reference"></a>static <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscCommBuildTwoSidedFReq_Reference(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> ntags, MPI_Request **toreqs, MPI_Request **fromreqs, <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*send)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*recv)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), void *ctx)</font></strong>
<a name="line287">287: </a>{
<a name="line288">288: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>  i, *tag;
<a name="line289">289: </a>  MPI_Aint     lb, unitbytes;
<a name="line290">290: </a>  MPI_Request *sendreq, *recvreq;

<a name="line292">292: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(ntags, &amp;tag);
<a name="line293">293: </a>  <font color="#4169E1">if</font> (ntags &gt; 0) <a href="../../../docs/manualpages/Sys/PetscCommDuplicate.html">PetscCommDuplicate</a>(comm, &amp;comm, &amp;tag[0]);
<a name="line294">294: </a>  <font color="#4169E1">for</font> (i = 1; i &lt; ntags; i++) <a href="../../../docs/manualpages/Sys/PetscCommGetNewTag.html">PetscCommGetNewTag</a>(comm, &amp;tag[i]);

<a name="line296">296: </a>  <font color="#B22222">/* Perform complete initial rendezvous */</font>
<a name="line297">297: </a>  <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata);

<a name="line299">299: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nto * ntags, &amp;sendreq);
<a name="line300">300: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(*nfrom * ntags, &amp;recvreq);

<a name="line302">302: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Type_get_extent.html#MPI_Type_get_extent">MPI_Type_get_extent</a>(dtype, &amp;lb, &amp;unitbytes);
<a name="line304">304: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) {
<a name="line305">305: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> k;
<a name="line306">306: </a>    <font color="#4169E1">for</font> (k = 0; k &lt; ntags; k++) sendreq[i * ntags + k] = MPI_REQUEST_NULL;
<a name="line307">307: </a>    (*send)(comm, tag, i, toranks[i], ((char *)todata) + count * unitbytes * i, sendreq + i * ntags, ctx);
<a name="line308">308: </a>  }
<a name="line309">309: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; *nfrom; i++) {
<a name="line310">310: </a>    void       *header = (*(char **)fromdata) + count * unitbytes * i;
<a name="line311">311: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> k;
<a name="line312">312: </a>    <font color="#4169E1">for</font> (k = 0; k &lt; ntags; k++) recvreq[i * ntags + k] = MPI_REQUEST_NULL;
<a name="line313">313: </a>    (*recv)(comm, tag, (*fromranks)[i], header, recvreq + i * ntags, ctx);
<a name="line314">314: </a>  }
<a name="line315">315: </a>  <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(tag);
<a name="line316">316: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDestroy.html">PetscCommDestroy</a>(&amp;comm);
<a name="line317">317: </a>  *toreqs   = sendreq;
<a name="line318">318: </a>  *fromreqs = recvreq;
<a name="line319">319: </a>  <font color="#4169E1">return</font> 0;
<a name="line320">320: </a>}

<a name="line322">322: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_NONBLOCKING_COLLECTIVES)</font>

<a name="line324">324: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedFReq_Ibarrier"></a>static <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> PetscCommBuildTwoSidedFReq_Ibarrier(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> ntags, MPI_Request **toreqs, MPI_Request **fromreqs, <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*send)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*recv)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), void *ctx)</font></strong>
<a name="line325">325: </a>{
<a name="line326">326: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>    nrecvs, tag, *tags, done, i;
<a name="line327">327: </a>  MPI_Aint       lb, unitbytes;
<a name="line328">328: </a>  char          *tdata;
<a name="line329">329: </a>  MPI_Request   *sendreqs, *usendreqs, *req, barrier;
<a name="line330">330: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBuffer.html">PetscSegBuffer</a> segrank, segdata, segreq;
<a name="line331">331: </a>  <a href="../../../docs/manualpages/Sys/PetscBool.html">PetscBool</a>      barrier_started;

<a name="line333">333: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDuplicate.html">PetscCommDuplicate</a>(comm, &amp;comm, &amp;tag);
<a name="line334">334: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(ntags, &amp;tags);
<a name="line335">335: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; ntags; i++) <a href="../../../docs/manualpages/Sys/PetscCommGetNewTag.html">PetscCommGetNewTag</a>(comm, &amp;tags[i]);
<a name="line336">336: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Type_get_extent.html#MPI_Type_get_extent">MPI_Type_get_extent</a>(dtype, &amp;lb, &amp;unitbytes);
<a name="line338">338: </a>  tdata = (char *)todata;
<a name="line339">339: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nto, &amp;sendreqs);
<a name="line340">340: </a>  <a href="../../../docs/manualpages/Sys/PetscMalloc1.html">PetscMalloc1</a>(nto * ntags, &amp;usendreqs);
<a name="line341">341: </a>  <font color="#B22222">/* Post synchronous sends */</font>
<a name="line342">342: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Issend.html#MPI_Issend">MPI_Issend</a>((void *)(tdata + count * unitbytes * i), count, dtype, toranks[i], tag, comm, sendreqs + i);
<a name="line343">343: </a>  <font color="#B22222">/* Post actual payloads.  These are typically larger messages.  Hopefully sending these later does not slow down the</font>
<a name="line344">344: </a><font color="#B22222">   * synchronous messages above. */</font>
<a name="line345">345: </a>  <font color="#4169E1">for</font> (i = 0; i &lt; nto; i++) {
<a name="line346">346: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> k;
<a name="line347">347: </a>    <font color="#4169E1">for</font> (k = 0; k &lt; ntags; k++) usendreqs[i * ntags + k] = MPI_REQUEST_NULL;
<a name="line348">348: </a>    (*send)(comm, tags, i, toranks[i], tdata + count * unitbytes * i, usendreqs + i * ntags, ctx);
<a name="line349">349: </a>  }

<a name="line351">351: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferCreate.html">PetscSegBufferCreate</a>(<font color="#4169E1">sizeof</font>(<a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>), 4, &amp;segrank);
<a name="line352">352: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferCreate.html">PetscSegBufferCreate</a>(unitbytes, 4 * count, &amp;segdata);
<a name="line353">353: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferCreate.html">PetscSegBufferCreate</a>(<font color="#4169E1">sizeof</font>(MPI_Request), 4, &amp;segreq);

<a name="line355">355: </a>  nrecvs  = 0;
<a name="line356">356: </a>  barrier = MPI_REQUEST_NULL;
<a name="line357">357: </a>  <font color="#B22222">/* MPICH-3.2 sometimes does not create a request in some "optimized" cases.  This is arguably a standard violation,</font>
<a name="line358">358: </a><font color="#B22222">   * but we need to work around it. */</font>
<a name="line359">359: </a>  barrier_started = <a href="../../../docs/manualpages/Sys/PETSC_FALSE.html">PETSC_FALSE</a>;
<a name="line360">360: </a>  <font color="#4169E1">for</font> (done = 0; !done;) {
<a name="line361">361: </a>    <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> flag;
<a name="line362">362: </a>    MPI_Status  status;
<a name="line363">363: </a>    <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Iprobe.html#MPI_Iprobe">MPI_Iprobe</a>(MPI_ANY_SOURCE, tag, comm, &amp;flag, &amp;status);
<a name="line364">364: </a>    <font color="#4169E1">if</font> (flag) { <font color="#B22222">/* incoming message */</font>
<a name="line365">365: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *recvrank, k;
<a name="line366">366: </a>      void        *buf;
<a name="line367">367: </a>      <a href="../../../docs/manualpages/Sys/PetscSegBufferGet.html">PetscSegBufferGet</a>(segrank, 1, &amp;recvrank);
<a name="line368">368: </a>      <a href="../../../docs/manualpages/Sys/PetscSegBufferGet.html">PetscSegBufferGet</a>(segdata, count, &amp;buf);
<a name="line369">369: </a>      *recvrank = status.MPI_SOURCE;
<a name="line370">370: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Recv.html#MPI_Recv">MPI_Recv</a>(buf, count, dtype, status.MPI_SOURCE, tag, comm, MPI_STATUS_IGNORE);
<a name="line371">371: </a>      <a href="../../../docs/manualpages/Sys/PetscSegBufferGet.html">PetscSegBufferGet</a>(segreq, ntags, &amp;req);
<a name="line372">372: </a>      <font color="#4169E1">for</font> (k = 0; k &lt; ntags; k++) req[k] = MPI_REQUEST_NULL;
<a name="line373">373: </a>      (*recv)(comm, tags, status.MPI_SOURCE, buf, req, ctx);
<a name="line374">374: </a>      nrecvs++;
<a name="line375">375: </a>    }
<a name="line376">376: </a>    <font color="#4169E1">if</font> (!barrier_started) {
<a name="line377">377: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> sent, nsends;
<a name="line378">378: </a>      <a href="../../../docs/manualpages/Sys/PetscMPIIntCast.html">PetscMPIIntCast</a>(nto, &amp;nsends);
<a name="line379">379: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Testall.html#MPI_Testall">MPI_Testall</a>(nsends, sendreqs, &amp;sent, MPI_STATUSES_IGNORE);
<a name="line380">380: </a>      <font color="#4169E1">if</font> (sent) {
<a name="line381">381: </a>        <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a>(comm, &amp;barrier);
<a name="line382">382: </a>        barrier_started = <a href="../../../docs/manualpages/Sys/PETSC_TRUE.html">PETSC_TRUE</a>;
<a name="line383">383: </a>      }
<a name="line384">384: </a>    } <font color="#4169E1">else</font> {
<a name="line385">385: </a>      <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Test.html#MPI_Test">MPI_Test</a>(&amp;barrier, &amp;done, MPI_STATUS_IGNORE);
<a name="line386">386: </a>    }
<a name="line387">387: </a>  }
<a name="line388">388: </a>  *nfrom = nrecvs;
<a name="line389">389: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferExtractAlloc.html">PetscSegBufferExtractAlloc</a>(segrank, fromranks);
<a name="line390">390: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferDestroy.html">PetscSegBufferDestroy</a>(&amp;segrank);
<a name="line391">391: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferExtractAlloc.html">PetscSegBufferExtractAlloc</a>(segdata, fromdata);
<a name="line392">392: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferDestroy.html">PetscSegBufferDestroy</a>(&amp;segdata);
<a name="line393">393: </a>  *toreqs = usendreqs;
<a name="line394">394: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferExtractAlloc.html">PetscSegBufferExtractAlloc</a>(segreq, fromreqs);
<a name="line395">395: </a>  <a href="../../../docs/manualpages/Sys/PetscSegBufferDestroy.html">PetscSegBufferDestroy</a>(&amp;segreq);
<a name="line396">396: </a>  <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(sendreqs);
<a name="line397">397: </a>  <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(tags);
<a name="line398">398: </a>  <a href="../../../docs/manualpages/Sys/PetscCommDestroy.html">PetscCommDestroy</a>(&amp;comm);
<a name="line399">399: </a>  <font color="#4169E1">return</font> 0;
<a name="line400">400: </a>}
<a name="line401">401: </a><font color="#A020F0">#endif</font>

<a name="line403">403: </a><font color="#B22222">/*@C</font>
<a name="line404">404: </a><font color="#B22222">   <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedF.html">PetscCommBuildTwoSidedF</a> - discovers communicating ranks given one-sided information, calling user-defined functions during rendezvous</font>

<a name="line406">406: </a><font color="#B22222">   Collective</font>

<a name="line408">408: </a><font color="#B22222">   Input Parameters:</font>
<a name="line409">409: </a><font color="#B22222">+  comm - communicator</font>
<a name="line410">410: </a><font color="#B22222">.  count - number of entries to send/receive in initial rendezvous (must match on all ranks)</font>
<a name="line411">411: </a><font color="#B22222">.  dtype - datatype to send/receive from each rank (must match on all ranks)</font>
<a name="line412">412: </a><font color="#B22222">.  nto - number of ranks to send data to</font>
<a name="line413">413: </a><font color="#B22222">.  toranks - ranks to send to (array of length nto)</font>
<a name="line414">414: </a><font color="#B22222">.  todata - data to send to each rank (packed)</font>
<a name="line415">415: </a><font color="#B22222">.  ntags - number of tags needed by send/recv callbacks</font>
<a name="line416">416: </a><font color="#B22222">.  send - callback invoked on sending process when ready to send primary payload</font>
<a name="line417">417: </a><font color="#B22222">.  recv - callback invoked on receiving process after delivery of rendezvous message</font>
<a name="line418">418: </a><font color="#B22222">-  ctx - context for callbacks</font>

<a name="line420">420: </a><font color="#B22222">   Output Parameters:</font>
<a name="line421">421: </a><font color="#B22222">+  nfrom - number of ranks receiving messages from</font>
<a name="line422">422: </a><font color="#B22222">.  fromranks - ranks receiving messages from (length nfrom; caller should `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>
<a name="line423">423: </a><font color="#B22222">-  fromdata - packed data from each rank, each with count entries of type dtype (length nfrom, caller responsible for `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>

<a name="line425">425: </a><font color="#B22222">   Level: developer</font>

<a name="line427">427: </a><font color="#B22222">   Notes:</font>
<a name="line428">428: </a><font color="#B22222">   This memory-scalable interface is an alternative to calling `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()` and</font>
<a name="line429">429: </a><font color="#B22222">   `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`, possibly with a subsequent round of communication to send other data.</font>

<a name="line431">431: </a><font color="#B22222">   Basic data types as well as contiguous types are supported, but non-contiguous (e.g., strided) types are not.</font>

<a name="line433">433: </a><font color="#B22222">   References:</font>
<a name="line434">434: </a><font color="#B22222">.  * - Hoefler, Siebert and Lumsdaine, The <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a> implementation uses the algorithm in</font>
<a name="line435">435: </a><font color="#B22222">   Scalable communication protocols for dynamic sparse data exchange, 2010.</font>

<a name="line437">437: </a><font color="#B22222">.seealso: `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`, `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedFReq.html">PetscCommBuildTwoSidedFReq</a>()`, `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()`, `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`</font>
<a name="line438">438: </a><font color="#B22222">@*/</font>
<a name="line439">439: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedF"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedF.html">PetscCommBuildTwoSidedF</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> ntags, <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*send)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*recv)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), void *ctx)</font></strong>
<a name="line440">440: </a>{
<a name="line441">441: </a>  MPI_Request *toreqs, *fromreqs;

<a name="line443">443: </a>  <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedFReq.html">PetscCommBuildTwoSidedFReq</a>(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata, ntags, &amp;toreqs, &amp;fromreqs, send, recv, ctx);
<a name="line444">444: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(nto * ntags, toreqs, MPI_STATUSES_IGNORE);
<a name="line445">445: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Waitall.html#MPI_Waitall">MPI_Waitall</a>(*nfrom * ntags, fromreqs, MPI_STATUSES_IGNORE);
<a name="line446">446: </a>  <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(toreqs);
<a name="line447">447: </a>  <a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>(fromreqs);
<a name="line448">448: </a>  <font color="#4169E1">return</font> 0;
<a name="line449">449: </a>}

<a name="line451">451: </a><font color="#B22222">/*@C</font>
<a name="line452">452: </a><font color="#B22222">   <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedFReq.html">PetscCommBuildTwoSidedFReq</a> - discovers communicating ranks given one-sided information, calling user-defined functions during rendezvous, returns requests</font>

<a name="line454">454: </a><font color="#B22222">   Collective</font>

<a name="line456">456: </a><font color="#B22222">   Input Parameters:</font>
<a name="line457">457: </a><font color="#B22222">+  comm - communicator</font>
<a name="line458">458: </a><font color="#B22222">.  count - number of entries to send/receive in initial rendezvous (must match on all ranks)</font>
<a name="line459">459: </a><font color="#B22222">.  dtype - datatype to send/receive from each rank (must match on all ranks)</font>
<a name="line460">460: </a><font color="#B22222">.  nto - number of ranks to send data to</font>
<a name="line461">461: </a><font color="#B22222">.  toranks - ranks to send to (array of length nto)</font>
<a name="line462">462: </a><font color="#B22222">.  todata - data to send to each rank (packed)</font>
<a name="line463">463: </a><font color="#B22222">.  ntags - number of tags needed by send/recv callbacks</font>
<a name="line464">464: </a><font color="#B22222">.  send - callback invoked on sending process when ready to send primary payload</font>
<a name="line465">465: </a><font color="#B22222">.  recv - callback invoked on receiving process after delivery of rendezvous message</font>
<a name="line466">466: </a><font color="#B22222">-  ctx - context for callbacks</font>

<a name="line468">468: </a><font color="#B22222">   Output Parameters:</font>
<a name="line469">469: </a><font color="#B22222">+  nfrom - number of ranks receiving messages from</font>
<a name="line470">470: </a><font color="#B22222">.  fromranks - ranks receiving messages from (length nfrom; caller should `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>
<a name="line471">471: </a><font color="#B22222">.  fromdata - packed data from each rank, each with count entries of type dtype (length nfrom, caller responsible for `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>
<a name="line472">472: </a><font color="#B22222">.  toreqs - array of nto*ntags sender requests (caller must wait on these, then `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>
<a name="line473">473: </a><font color="#B22222">-  fromreqs - array of nfrom*ntags receiver requests (caller must wait on these, then `<a href="../../../docs/manualpages/Sys/PetscFree.html">PetscFree</a>()`)</font>

<a name="line475">475: </a><font color="#B22222">   Level: developer</font>

<a name="line477">477: </a><font color="#B22222">   Notes:</font>
<a name="line478">478: </a><font color="#B22222">   This memory-scalable interface is an alternative to calling `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()` and</font>
<a name="line479">479: </a><font color="#B22222">   `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`, possibly with a subsequent round of communication to send other data.</font>

<a name="line481">481: </a><font color="#B22222">   Basic data types as well as contiguous types are supported, but non-contiguous (e.g., strided) types are not.</font>

<a name="line483">483: </a><font color="#B22222">   References:</font>
<a name="line484">484: </a><font color="#B22222">.  * - Hoefler, Siebert and Lumsdaine, The <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a> implementation uses the algorithm in</font>
<a name="line485">485: </a><font color="#B22222">   Scalable communication protocols for dynamic sparse data exchange, 2010.</font>

<a name="line487">487: </a><font color="#B22222">.seealso: `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSided.html">PetscCommBuildTwoSided</a>()`, `<a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedF.html">PetscCommBuildTwoSidedF</a>()`, `<a href="../../../docs/manualpages/Sys/PetscGatherNumberOfMessages.html">PetscGatherNumberOfMessages</a>()`, `<a href="../../../docs/manualpages/Sys/PetscGatherMessageLengths.html">PetscGatherMessageLengths</a>()`</font>
<a name="line488">488: </a><font color="#B22222">@*/</font>
<a name="line489">489: </a><strong><font color="#4169E1"><a name="PetscCommBuildTwoSidedFReq"></a><a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedFReq.html">PetscCommBuildTwoSidedFReq</a>(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a> comm, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> count, MPI_Datatype dtype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> nto, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *toranks, const void *todata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *nfrom, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **fromranks, void *fromdata, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> ntags, MPI_Request **toreqs, MPI_Request **fromreqs, <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*send)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*recv)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), void *ctx)</font></strong>
<a name="line490">490: </a>{
<a name="line491">491: </a>  <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*f)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, MPI_Datatype, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], const void *, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> *, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a> **, void *, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, MPI_Request **, MPI_Request **, <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*send)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), <a href="../../../docs/manualpages/Sys/PetscErrorCode.html">PetscErrorCode</a> (*recv)(<a href="../../../docs/manualpages/Sys/MPI_Comm.html">MPI_Comm</a>, const <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>[], <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>, void *, MPI_Request[], void *), void *ctx);
<a name="line492">492: </a>  <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PetscBuildTwoSidedType</a> buildtype = <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_NOTSET</a>;
<a name="line493">493: </a>  <a href="../../../docs/manualpages/Sys/PetscMPIInt.html">PetscMPIInt</a>            i, size;

<a name="line495">495: </a>  <a href="../../../docs/manualpages/Viewer/PetscSysInitializePackage.html">PetscSysInitializePackage</a>();
<a name="line496">496: </a>  <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Comm_size.html#MPI_Comm_size">MPI_Comm_size</a>(comm, &amp;size);
<a name="line498">498: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventSync.html">PetscLogEventSync</a>(PETSC_BuildTwoSidedF, comm);
<a name="line499">499: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventBegin.html">PetscLogEventBegin</a>(PETSC_BuildTwoSidedF, 0, 0, 0, 0);
<a name="line500">500: </a>  <a href="../../../docs/manualpages/Sys/PetscCommBuildTwoSidedGetType.html">PetscCommBuildTwoSidedGetType</a>(comm, &amp;buildtype);
<a name="line501">501: </a>  <font color="#4169E1">switch</font> (buildtype) {
<a name="line502">502: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_IBARRIER</a>:
<a name="line503">503: </a><font color="#A020F0">#if defined(PETSC_HAVE_MPI_NONBLOCKING_COLLECTIVES)</font>
<a name="line504">504: </a>    f = PetscCommBuildTwoSidedFReq_Ibarrier;
<a name="line505">505: </a>    <font color="#4169E1">break</font>;
<a name="line506">506: </a><font color="#A020F0">#else</font>
<a name="line507">507: </a>    <a href="../../../docs/manualpages/Sys/SETERRQ.html">SETERRQ</a>(comm, PETSC_ERR_PLIB, <font color="#666666">"MPI implementation does not provide <a href="http://www.mpich.org/static/docs/latest/www3/MPI_Ibarrier.html#MPI_Ibarrier">MPI_Ibarrier</a> (part of MPI-3)"</font>);
<a name="line508">508: </a><font color="#A020F0">#endif</font>
<a name="line509">509: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_ALLREDUCE</a>:
<a name="line510">510: </a>  <font color="#4169E1">case</font> <a href="../../../docs/manualpages/Sys/PetscBuildTwoSidedType.html">PETSC_BUILDTWOSIDED_REDSCATTER</a>:
<a name="line511">511: </a>    f = PetscCommBuildTwoSidedFReq_Reference;
<a name="line512">512: </a>    <font color="#4169E1">break</font>;
<a name="line513">513: </a><strong><font color="#FF0000">  default:</font></strong>
<a name="line514">514: </a>    <a href="../../../docs/manualpages/Sys/SETERRQ.html">SETERRQ</a>(comm, PETSC_ERR_PLIB, <font color="#666666">"Unknown method for building two-sided communication"</font>);
<a name="line515">515: </a>  }
<a name="line516">516: </a>  (*f)(comm, count, dtype, nto, toranks, todata, nfrom, fromranks, fromdata, ntags, toreqs, fromreqs, send, recv, ctx);
<a name="line517">517: </a>  <a href="../../../docs/manualpages/Profiling/PetscLogEventEnd.html">PetscLogEventEnd</a>(PETSC_BuildTwoSidedF, 0, 0, 0, 0);
<a name="line518">518: </a>  <font color="#4169E1">return</font> 0;
<a name="line519">519: </a>}
</pre>
</body>

</html>
